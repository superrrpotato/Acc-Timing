{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import global_v as glv\n",
    "from network_parser import parse\n",
    "from datasets import loadMNIST, loadXOR\n",
    "from utils import learningStats\n",
    "from datetime import datetime\n",
    "import cnns\n",
    "import argparse\n",
    "import loss\n",
    "import logging\n",
    "\n",
    "max_accuracu = 0\n",
    "min_loss = 1000\n",
    "\n",
    "def train(network, trainloader, opti, epoch, states, network_config,\\\n",
    "        layers_config, err):\n",
    "    global max_accuracy\n",
    "    global min_loss\n",
    "    logging.info('\\nEpoch: %d', epoch)\n",
    "    train_loss = correct = total = 0\n",
    "    n_steps = network_config['n_steps']\n",
    "#    n_class = network_config['n_class']\n",
    "    batch_size = network_config['batch_size']\n",
    "    time = datetime.now()\n",
    "    des_str = \"Training @ epoch \" + str(epoch)\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "         if network_config[\"rule\"] == \"ATBP\":\n",
    "             if len(inputs.shape) < 5:\n",
    "                 inputs = inputs.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "             labels = labels.to(glv.device)\n",
    "             inputs = inputs.to(glv.device)\n",
    "             inputs.type(glv.dtype)\n",
    "             outputs = network.forward(inputs, epoch, True)\n",
    "             if network_config['loss'] == \"average\":\n",
    "                 target = labels\n",
    "                 loss = err.average(outputs, target)\n",
    "             opti.zero_grad()\n",
    "             loss.backward()\n",
    "             opti.step()\n",
    "             train_loss += torch.sum(loss).item()\n",
    "             total += len(labels)\n",
    "         else:\n",
    "             raise Exception('Unrecognized rule name.')\n",
    "         states.training.numSamples = total\n",
    "         states.training.lossSum += loss.cpu().data.item()\n",
    "         states.print(epoch, batch_idx, (datetime.now()-time).total_seconds(),\\\n",
    "                 opti.param_groups[0]['lr'])\n",
    "    total_loss = train_loss/total\n",
    "    if total_loss < min_loss:\n",
    "        min_loss = total_loss\n",
    "    logging.info(\"Training Loss:  %.3f (%.3f)\\n\", total_loss, min_loss)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-config', action='store', dest='config',\\\n",
    "            help='The path of config file')\n",
    "    parser.add_argument('-checkpoint', action='store', dest='checkpoint',\\\n",
    "            help='The path of checkpoint, if use checkpoint')\n",
    "    try:\n",
    "        args = parser.parse_args()\n",
    "    except:\n",
    "        parser.print_help()\n",
    "        exit(0)\n",
    "    if args.config is None:\n",
    "        raise Exception('Unrecognized config file.')\n",
    "    else:\n",
    "        config_path = args.config\n",
    "    logging.basicConfig(filename='result.log', level=logging.INFO)\n",
    "    logging.info(\"start parsing settings\")\n",
    "    params = parse(config_path)\n",
    "    logging.info(\"finish parsing settings\")\n",
    "    glv.init(params)\n",
    "    logging.info(\"start loading dataset\")\n",
    "    if params['Network']['dataset'] == \"MNIST\":\n",
    "        data_path = os.path.expanduser(params['Network']['data_path'])\n",
    "        train_loader, test_loader = loadMNIST.get_mnist(data_path,\\\n",
    "                params['Network'])\n",
    "    elif params['Network']['dataset'] == \"XOR\":\n",
    "        train_loader, test_loader = loadXOR.get_XOR(params['Network'])\n",
    "    else:\n",
    "        raise Exception('Unrecognized dataset name.')\n",
    "    logging.info(\"dataset loaded\")\n",
    "    net = cnns.Network(params['Network'], params['Layers'],\\\n",
    "            list(train_loader.dataset[0][0].shape)).to(glv.device)\n",
    "    if args.checkpoint is not None:\n",
    "        checkpoint_path = args.checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "    error = loss.SpikeLoss(params['Network']).to(glv.device)\n",
    "    optimizer = torch.optim.AdamW(net.get_parameters(),\\\n",
    "            lr=params['Network']['lr'], betas=(0.9, 0.999))\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    l_states = learningStats()\n",
    "    decayRate = params['Network']['lr_dacay']\n",
    "    my_lr_scheduler =\\\n",
    "    torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer,\\\n",
    "            gamma=decayRate)\n",
    "    for e in range(params['Network']['epochs']):\n",
    "        l_states.training.reset()\n",
    "        train(net, train_loader, optimizer, e, l_states,\\\n",
    "                params['Network'], params['Layers'], error)\n",
    "        l_states.training.update()\n",
    "        my_lr_scheduler.step()\n",
    "#        l_states.testing.reset()\n",
    "#        test(net, test_loader, e, l_states, params['Network'],\\\n",
    "#                params['Layers'])\n",
    "#        l_states.testing.update()\n",
    "#    logging.info(\"Best Accuracy: %.3f, at epoch: %d \\n\", best_acc, best_epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
