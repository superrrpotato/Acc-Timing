{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import global_v as glv\n",
    "from network_parser import parse\n",
    "from datasets import loadXOR\n",
    "from utils import learningStats\n",
    "from datetime import datetime\n",
    "import cnns\n",
    "import argparse\n",
    "import loss\n",
    "import logging\n",
    "\n",
    "max_accuracu = 0\n",
    "min_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def save_fig(name):\n",
    "    if str(name)[:3] == 'mem':\n",
    "        np.save(\"figs/\"+str(name),glv.mem_p_stat_ori)\n",
    "    elif str(name)[:3] == 'out':\n",
    "        np.save(\"figs/\"+str(name),glv.output_stat_ori)\n",
    "    elif str(name)[:3] == 'err':\n",
    "        np.save(\"figs/\"+str(name),glv.error_stat)\n",
    "    elif str(name)[:3] == 'gra':\n",
    "        np.save(\"figs/\"+str(name),glv.grad_stat)\n",
    "        \n",
    "def plot_mov_fig():\n",
    "    fig_num=4\n",
    "    plt.clf()\n",
    "    \n",
    "    for key in glv.mem_p_stat_ori:\n",
    "        \n",
    "        if key == 'FC_1':\n",
    "            count = 1\n",
    "            layer_shape = np.shape(np.array(glv.mem_p_stat_ori[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "            cases_ori = np.array(glv.mem_p_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(cases_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            output_ori = np.array(glv.output_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(output_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "        elif key == 'FC_2':\n",
    "            count = 5\n",
    "            layer_shape = np.shape(np.array(glv.mem_p_stat_ori[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "            cases_ori = np.array(glv.mem_p_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            print(\"cases_num: \", cases_num)\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(cases_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            output_ori = np.array(glv.output_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(output_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "def plot_grad_fig():\n",
    "    fig_num=4\n",
    "    \n",
    "    for key in glv.grad_stat:\n",
    "        \n",
    "        if key == 'FC_1':\n",
    "            count = 3\n",
    "            layer_shape = np.shape(np.array(glv.grad_stat[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "\n",
    "            grad_stat = np.array(glv.grad_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(grad_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            error_stat = np.array(glv.error_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(error_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "            count = count + 1\n",
    "        elif key == 'FC_2':\n",
    "            count = 7\n",
    "            layer_shape = np.shape(np.array(glv.grad_stat[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "\n",
    "            grad_stat = np.array(glv.grad_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(grad_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            error_stat = np.array(glv.error_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(error_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading XOR\n",
      "Network Structure:\n",
      "linear\n",
      "FC_1\n",
      "input shape: [10, 2, 1, 1, 50]\n",
      "weight shape:  [2, 40]\n",
      "output shape: [10, 40, 1, 1, 50]\n",
      "-----------------------------------------\n",
      "linear\n",
      "FC_2\n",
      "input shape: [10, 40, 1, 1, 50]\n",
      "weight shape:  [40, 1]\n",
      "output shape: [10, 1, 1, 1, 50]\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "tensor([-0.5538,  0.8829,  0.9211, -0.3970, -0.9915,  0.9921, -0.7636, -0.2286,\n",
      "         0.0021, -0.8685])\n",
      "torch.Size([10, 2, 1, 1, 50])\n",
      "torch.Size([10])\n",
      "times_count: 0\n",
      "scale: 1.0000, bias: 0.0000\n",
      "cases_num:  10\n",
      "times_count: 1\n",
      "scale: 0.9899, bias: -0.0100\n",
      "cases_num:  10\n",
      "times_count: 2\n",
      "scale: 0.9799, bias: -0.0199\n",
      "cases_num:  10\n",
      "times_count: 3\n",
      "scale: 0.9703, bias: -0.0297\n",
      "cases_num:  10\n",
      "times_count: 4\n",
      "scale: 0.9611, bias: -0.0393\n",
      "cases_num:  10\n",
      "times_count: 5\n",
      "scale: 0.9524, bias: -0.0487\n",
      "cases_num:  10\n",
      "times_count: 6\n",
      "scale: 0.9440, bias: -0.0579\n",
      "cases_num:  10\n",
      "times_count: 7\n",
      "scale: 0.9362, bias: -0.0670\n",
      "cases_num:  10\n",
      "times_count: 8\n",
      "scale: 0.9289, bias: -0.0760\n",
      "cases_num:  10\n",
      "times_count: 9\n",
      "scale: 0.9223, bias: -0.0847\n",
      "cases_num:  10\n",
      "times_count: 10\n",
      "scale: 0.9165, bias: -0.0931\n",
      "cases_num:  10\n",
      "times_count: 11\n",
      "scale: 0.9115, bias: -0.1014\n",
      "cases_num:  10\n",
      "times_count: 12\n",
      "scale: 0.9073, bias: -0.1093\n",
      "cases_num:  10\n",
      "times_count: 13\n",
      "scale: 0.9040, bias: -0.1171\n",
      "cases_num:  10\n",
      "times_count: 14\n",
      "scale: 0.9015, bias: -0.1247\n",
      "cases_num:  10\n",
      "times_count: 15\n",
      "scale: 0.8999, bias: -0.1322\n",
      "cases_num:  10\n",
      "times_count: 16\n",
      "scale: 0.8989, bias: -0.1396\n",
      "cases_num:  10\n",
      "times_count: 17\n",
      "scale: 0.8987, bias: -0.1469\n",
      "cases_num:  10\n",
      "times_count: 18\n",
      "scale: 0.8992, bias: -0.1542\n",
      "cases_num:  10\n",
      "times_count: 19\n",
      "scale: 0.9003, bias: -0.1615\n",
      "cases_num:  10\n",
      "times_count: 20\n",
      "scale: 0.9020, bias: -0.1687\n",
      "cases_num:  10\n",
      "times_count: 21\n",
      "scale: 0.9043, bias: -0.1758\n",
      "cases_num:  10\n",
      "times_count: 22\n",
      "scale: 0.9070, bias: -0.1830\n",
      "cases_num:  10\n",
      "times_count: 23\n",
      "scale: 0.9101, bias: -0.1901\n",
      "cases_num:  10\n",
      "times_count: 24\n",
      "scale: 0.9137, bias: -0.1973\n",
      "cases_num:  10\n",
      "times_count: 25\n",
      "scale: 0.9175, bias: -0.2046\n",
      "cases_num:  10\n",
      "times_count: 26\n",
      "scale: 0.9217, bias: -0.2119\n",
      "cases_num:  10\n",
      "times_count: 27\n",
      "scale: 0.9260, bias: -0.2194\n",
      "cases_num:  10\n",
      "times_count: 28\n",
      "scale: 0.9305, bias: -0.2269\n",
      "cases_num:  10\n",
      "times_count: 29\n",
      "scale: 0.9353, bias: -0.2345\n",
      "cases_num:  10\n",
      "times_count: 30\n",
      "scale: 0.9402, bias: -0.2420\n",
      "cases_num:  10\n",
      "times_count: 31\n",
      "scale: 0.9453, bias: -0.2496\n",
      "cases_num:  10\n",
      "times_count: 32\n",
      "scale: 0.9506, bias: -0.2572\n",
      "cases_num:  10\n",
      "times_count: 33\n",
      "scale: 0.9560, bias: -0.2647\n",
      "cases_num:  10\n",
      "times_count: 34\n",
      "scale: 0.9616, bias: -0.2721\n",
      "cases_num:  10\n",
      "times_count: 35\n",
      "scale: 0.9673, bias: -0.2793\n",
      "cases_num:  10\n",
      "times_count: 36\n",
      "scale: 0.9732, bias: -0.2865\n",
      "cases_num:  10\n",
      "times_count: 37\n",
      "scale: 0.9793, bias: -0.2935\n",
      "cases_num:  10\n",
      "times_count: 38\n",
      "scale: 0.9854, bias: -0.3003\n",
      "cases_num:  10\n",
      "times_count: 39\n",
      "scale: 0.9917, bias: -0.3070\n",
      "cases_num:  10\n",
      "times_count: 40\n",
      "scale: 0.9982, bias: -0.3135\n",
      "cases_num:  10\n",
      "times_count: 41\n",
      "scale: 1.0047, bias: -0.3198\n",
      "cases_num:  10\n",
      "times_count: 42\n",
      "scale: 1.0113, bias: -0.3259\n",
      "cases_num:  10\n",
      "times_count: 43\n",
      "scale: 1.0181, bias: -0.3319\n",
      "cases_num:  10\n",
      "times_count: 44\n",
      "scale: 1.0249, bias: -0.3377\n",
      "cases_num:  10\n",
      "times_count: 45\n",
      "scale: 1.0318, bias: -0.3432\n",
      "cases_num:  10\n",
      "times_count: 46\n",
      "scale: 1.0387, bias: -0.3486\n",
      "cases_num:  10\n",
      "times_count: 47\n",
      "scale: 1.0458, bias: -0.3538\n",
      "cases_num:  10\n",
      "times_count: 48\n",
      "scale: 1.0529, bias: -0.3588\n",
      "cases_num:  10\n",
      "times_count: 49\n",
      "scale: 1.0600, bias: -0.3636\n",
      "cases_num:  10\n",
      "times_count: 50\n",
      "scale: 1.0672, bias: -0.3682\n",
      "cases_num:  10\n",
      "times_count: 51\n",
      "scale: 1.0744, bias: -0.3726\n",
      "cases_num:  10\n",
      "times_count: 52\n",
      "scale: 1.0817, bias: -0.3769\n",
      "cases_num:  10\n",
      "times_count: 53\n",
      "scale: 1.0890, bias: -0.3809\n",
      "cases_num:  10\n",
      "times_count: 54\n",
      "scale: 1.0963, bias: -0.3848\n",
      "cases_num:  10\n",
      "times_count: 55\n",
      "scale: 1.1036, bias: -0.3886\n",
      "cases_num:  10\n",
      "times_count: 56\n",
      "scale: 1.1109, bias: -0.3921\n",
      "cases_num:  10\n",
      "times_count: 57\n",
      "scale: 1.1182, bias: -0.3955\n",
      "cases_num:  10\n",
      "times_count: 58\n",
      "scale: 1.1255, bias: -0.3988\n",
      "cases_num:  10\n",
      "times_count: 59\n",
      "scale: 1.1327, bias: -0.4019\n",
      "cases_num:  10\n",
      "times_count: 60\n",
      "scale: 1.1400, bias: -0.4049\n",
      "cases_num:  10\n",
      "times_count: 61\n",
      "scale: 1.1472, bias: -0.4078\n",
      "cases_num:  10\n",
      "times_count: 62\n",
      "scale: 1.1543, bias: -0.4106\n",
      "cases_num:  10\n",
      "times_count: 63\n",
      "scale: 1.1614, bias: -0.4132\n",
      "cases_num:  10\n",
      "times_count: 64\n",
      "scale: 1.1685, bias: -0.4158\n",
      "cases_num:  10\n",
      "times_count: 65\n",
      "scale: 1.1755, bias: -0.4183\n",
      "cases_num:  10\n",
      "times_count: 66\n",
      "scale: 1.1824, bias: -0.4207\n",
      "cases_num:  10\n",
      "times_count: 67\n",
      "scale: 1.1893, bias: -0.4230\n",
      "cases_num:  10\n",
      "times_count: 68\n",
      "scale: 1.1961, bias: -0.4253\n",
      "cases_num:  10\n",
      "times_count: 69\n",
      "scale: 1.2029, bias: -0.4275\n",
      "cases_num:  10\n",
      "times_count: 70\n",
      "scale: 1.2096, bias: -0.4296\n",
      "cases_num:  10\n",
      "times_count: 71\n",
      "scale: 1.2162, bias: -0.4316\n",
      "cases_num:  10\n",
      "times_count: 72\n",
      "scale: 1.2227, bias: -0.4337\n",
      "cases_num:  10\n",
      "times_count: 73\n",
      "scale: 1.2292, bias: -0.4356\n",
      "cases_num:  10\n",
      "times_count: 74\n",
      "scale: 1.2355, bias: -0.4375\n",
      "cases_num:  10\n",
      "times_count: 75\n",
      "scale: 1.2418, bias: -0.4394\n",
      "cases_num:  10\n",
      "times_count: 76\n",
      "scale: 1.2480, bias: -0.4413\n",
      "cases_num:  10\n",
      "times_count: 77\n",
      "scale: 1.2542, bias: -0.4431\n",
      "cases_num:  10\n",
      "times_count: 78\n",
      "scale: 1.2602, bias: -0.4449\n",
      "cases_num:  10\n",
      "times_count: 79\n",
      "scale: 1.2661, bias: -0.4466\n",
      "cases_num:  10\n",
      "times_count: 80\n",
      "scale: 1.2720, bias: -0.4484\n",
      "cases_num:  10\n",
      "times_count: 81\n",
      "scale: 1.2778, bias: -0.4501\n",
      "cases_num:  10\n",
      "times_count: 82\n",
      "scale: 1.2835, bias: -0.4518\n",
      "cases_num:  10\n",
      "times_count: 83\n",
      "scale: 1.2890, bias: -0.4535\n",
      "cases_num:  10\n",
      "times_count: 84\n",
      "scale: 1.2945, bias: -0.4553\n",
      "cases_num:  10\n",
      "times_count: 85\n",
      "scale: 1.2999, bias: -0.4570\n",
      "cases_num:  10\n",
      "times_count: 86\n",
      "scale: 1.3053, bias: -0.4588\n",
      "cases_num:  10\n",
      "times_count: 87\n",
      "scale: 1.3105, bias: -0.4606\n",
      "cases_num:  10\n",
      "times_count: 88\n",
      "scale: 1.3156, bias: -0.4625\n",
      "cases_num:  10\n",
      "times_count: 89\n",
      "scale: 1.3206, bias: -0.4644\n",
      "cases_num:  10\n",
      "times_count: 90\n",
      "scale: 1.3256, bias: -0.4664\n",
      "cases_num:  10\n",
      "times_count: 91\n",
      "scale: 1.3304, bias: -0.4684\n",
      "cases_num:  10\n",
      "times_count: 92\n",
      "scale: 1.3352, bias: -0.4703\n",
      "cases_num:  10\n",
      "times_count: 93\n",
      "scale: 1.3399, bias: -0.4723\n",
      "cases_num:  10\n",
      "times_count: 94\n",
      "scale: 1.3445, bias: -0.4742\n",
      "cases_num:  10\n",
      "times_count: 95\n",
      "scale: 1.3491, bias: -0.4761\n",
      "cases_num:  10\n",
      "times_count: 96\n",
      "scale: 1.3535, bias: -0.4780\n",
      "cases_num:  10\n",
      "times_count: 97\n",
      "scale: 1.3579, bias: -0.4799\n",
      "cases_num:  10\n",
      "times_count: 98\n",
      "scale: 1.3622, bias: -0.4817\n",
      "cases_num:  10\n",
      "times_count: 99\n",
      "scale: 1.3664, bias: -0.4836\n",
      "cases_num:  10\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "config_path = 'Config_files/XOR.yaml'\n",
    "params = parse(config_path)\n",
    "\n",
    "\n",
    "train_loader, test_loader = loadXOR.get_XOR(params['Network'])\n",
    "\n",
    "network_config = params['Network']\n",
    "n_steps = network_config['n_steps']\n",
    "batch_size = network_config['batch_size']\n",
    "epoch = 0\n",
    "glv.init(params)\n",
    "\n",
    "net = cnns.Network(params['Network'], params['Layers'],\\\n",
    "            list(train_loader.dataset[0][0].shape)).to(glv.device)\n",
    "\n",
    "err = loss.SpikeLoss(params['Network']).to(glv.device)\n",
    "optimizer = torch.optim.AdamW(net.get_parameters(),\\\n",
    "            lr=params['Network']['lr'], betas=(0.9, 0.999))\n",
    "flag = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "    if flag == 1:\n",
    "        break\n",
    "    flag=1\n",
    "targets = labels\n",
    "inputs.type(dtype)\n",
    "inputs = inputs.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "print(labels)\n",
    "print(inputs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "%matplotlib qt5\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for times_count in range(100):\n",
    "    \n",
    "    print(\"times_count:\", times_count)\n",
    "    save_fig('mem'+str(times_count))\n",
    "    save_fig('out'+str(times_count))\n",
    "    \n",
    "    outputs = net.forward(inputs, True)\n",
    "    plot_mov_fig()\n",
    "\n",
    "    loss_num = err.average(outputs, targets)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_num.backward()\n",
    "    plot_grad_fig()\n",
    "    plt.pause(0.01)\n",
    "    save_fig('err'+str(times_count))\n",
    "    save_fig('gra'+str(times_count))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
