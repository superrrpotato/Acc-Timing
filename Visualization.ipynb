{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import global_v as glv\n",
    "from network_parser import parse\n",
    "from datasets import loadXOR\n",
    "from utils import learningStats\n",
    "from datetime import datetime\n",
    "import cnns\n",
    "import argparse\n",
    "import loss\n",
    "import logging\n",
    "\n",
    "max_accuracu = 0\n",
    "min_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def save_fig(name):\n",
    "    if str(name)[:3] == 'mem':\n",
    "        np.save(\"figs/\"+str(name),glv.mem_p_stat_ori)\n",
    "    elif str(name)[:3] == 'out':\n",
    "        np.save(\"figs/\"+str(name),glv.output_stat_ori)\n",
    "    elif str(name)[:3] == 'err':\n",
    "        np.save(\"figs/\"+str(name),glv.error_stat)\n",
    "    elif str(name)[:3] == 'gra':\n",
    "        np.save(\"figs/\"+str(name),glv.grad_stat)\n",
    "        \n",
    "def plot_mov_fig():\n",
    "    fig_num=4\n",
    "    plt.clf()\n",
    "    \n",
    "    for key in glv.mem_p_stat_ori:\n",
    "        \n",
    "        if key == 'FC_1':\n",
    "            count = 1\n",
    "            layer_shape = np.shape(np.array(glv.mem_p_stat_ori[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "            cases_ori = np.array(glv.mem_p_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(cases_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            output_ori = np.array(glv.output_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(output_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "        elif key == 'FC_2':\n",
    "            count = 5\n",
    "            layer_shape = np.shape(np.array(glv.mem_p_stat_ori[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "            cases_ori = np.array(glv.mem_p_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            print(\"cases_num: \", cases_num)\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(cases_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            output_ori = np.array(glv.output_stat_ori[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(output_ori)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "def plot_grad_fig():\n",
    "    fig_num=4\n",
    "    \n",
    "    for key in glv.grad_stat:\n",
    "        \n",
    "        if key == 'FC_1':\n",
    "            count = 3\n",
    "            layer_shape = np.shape(np.array(glv.grad_stat[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "\n",
    "            grad_stat = np.array(glv.grad_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(grad_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            error_stat = np.array(glv.error_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(error_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "            count = count + 1\n",
    "        elif key == 'FC_2':\n",
    "            count = 7\n",
    "            layer_shape = np.shape(np.array(glv.grad_stat[key]))\n",
    "            cases_num = layer_shape[0]*layer_shape[1]*layer_shape[2]*layer_shape[3]\n",
    "\n",
    "            grad_stat = np.array(glv.grad_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(grad_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "\n",
    "            count = count + 1\n",
    "            error_stat = np.array(glv.error_stat[key]).reshape(cases_num,layer_shape[4])\n",
    "            plt.subplot(2,fig_num,count)\n",
    "            plt.imshow(error_stat)\n",
    "#             plt.colorbar()\n",
    "            plt.axis('off')\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading XOR\n",
      "Network Structure:\n",
      "linear\n",
      "FC_1\n",
      "input shape: [10, 2, 1, 1, 50]\n",
      "weight shape:  [2, 40]\n",
      "output shape: [10, 40, 1, 1, 50]\n",
      "-----------------------------------------\n",
      "linear\n",
      "FC_2\n",
      "input shape: [10, 40, 1, 1, 50]\n",
      "weight shape:  [40, 1]\n",
      "output shape: [10, 1, 1, 1, 50]\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "tensor([ 0.9243,  0.9487, -0.6094, -0.2075, -0.3820,  0.0875, -0.9724, -0.9853,\n",
      "        -0.2081, -0.7134])\n",
      "torch.Size([10, 2, 1, 1, 50])\n",
      "torch.Size([10])\n",
      "times_count: 0\n",
      "scale: 1.0000, bias: 0.0000\n",
      "cases_num:  10\n",
      "times_count: 1\n",
      "scale: 0.9999, bias: -0.0100\n",
      "cases_num:  10\n",
      "times_count: 2\n",
      "scale: 0.9998, bias: -0.0200\n",
      "cases_num:  10\n",
      "times_count: 3\n",
      "scale: 0.9997, bias: -0.0299\n",
      "cases_num:  10\n",
      "times_count: 4\n",
      "scale: 0.9996, bias: -0.0399\n",
      "cases_num:  10\n",
      "times_count: 5\n",
      "scale: 0.9995, bias: -0.0497\n",
      "cases_num:  10\n",
      "times_count: 6\n",
      "scale: 0.9994, bias: -0.0595\n",
      "cases_num:  10\n",
      "times_count: 7\n",
      "scale: 0.9993, bias: -0.0692\n",
      "cases_num:  10\n",
      "times_count: 8\n",
      "scale: 0.9992, bias: -0.0788\n",
      "cases_num:  10\n",
      "times_count: 9\n",
      "scale: 0.9991, bias: -0.0883\n",
      "cases_num:  10\n",
      "times_count: 10\n",
      "scale: 1.0038, bias: -0.0977\n",
      "cases_num:  10\n",
      "times_count: 11\n",
      "scale: 1.0102, bias: -0.1070\n",
      "cases_num:  10\n",
      "times_count: 12\n",
      "scale: 1.0157, bias: -0.1162\n",
      "cases_num:  10\n",
      "times_count: 13\n",
      "scale: 1.0225, bias: -0.1254\n",
      "cases_num:  10\n",
      "times_count: 14\n",
      "scale: 1.0302, bias: -0.1345\n",
      "cases_num:  10\n",
      "times_count: 15\n",
      "scale: 1.0379, bias: -0.1437\n",
      "cases_num:  10\n",
      "times_count: 16\n",
      "scale: 1.0463, bias: -0.1530\n",
      "cases_num:  10\n",
      "times_count: 17\n",
      "scale: 1.0553, bias: -0.1624\n",
      "cases_num:  10\n",
      "times_count: 18\n",
      "scale: 1.0648, bias: -0.1721\n",
      "cases_num:  10\n",
      "times_count: 19\n",
      "scale: 1.0748, bias: -0.1821\n",
      "cases_num:  10\n",
      "times_count: 20\n",
      "scale: 1.0847, bias: -0.1924\n",
      "cases_num:  10\n",
      "times_count: 21\n",
      "scale: 1.0937, bias: -0.2028\n",
      "cases_num:  10\n",
      "times_count: 22\n",
      "scale: 1.1028, bias: -0.2135\n",
      "cases_num:  10\n",
      "times_count: 23\n",
      "scale: 1.1089, bias: -0.2243\n",
      "cases_num:  10\n",
      "times_count: 24\n",
      "scale: 1.1123, bias: -0.2354\n",
      "cases_num:  10\n",
      "times_count: 25\n",
      "scale: 1.1139, bias: -0.2466\n",
      "cases_num:  10\n",
      "times_count: 26\n",
      "scale: 1.1141, bias: -0.2579\n",
      "cases_num:  10\n",
      "times_count: 27\n",
      "scale: 1.1124, bias: -0.2692\n",
      "cases_num:  10\n",
      "times_count: 28\n",
      "scale: 1.1093, bias: -0.2805\n",
      "cases_num:  10\n",
      "times_count: 29\n",
      "scale: 1.1052, bias: -0.2919\n",
      "cases_num:  10\n",
      "times_count: 30\n",
      "scale: 1.1009, bias: -0.3031\n",
      "cases_num:  10\n",
      "times_count: 31\n",
      "scale: 1.0978, bias: -0.3141\n",
      "cases_num:  10\n",
      "times_count: 32\n",
      "scale: 1.0970, bias: -0.3247\n",
      "cases_num:  10\n",
      "times_count: 33\n",
      "scale: 1.0983, bias: -0.3351\n",
      "cases_num:  10\n",
      "times_count: 34\n",
      "scale: 1.1013, bias: -0.3451\n",
      "cases_num:  10\n",
      "times_count: 35\n",
      "scale: 1.1059, bias: -0.3547\n",
      "cases_num:  10\n",
      "times_count: 36\n",
      "scale: 1.1120, bias: -0.3640\n",
      "cases_num:  10\n",
      "times_count: 37\n",
      "scale: 1.1192, bias: -0.3727\n",
      "cases_num:  10\n",
      "times_count: 38\n",
      "scale: 1.1273, bias: -0.3811\n",
      "cases_num:  10\n",
      "times_count: 39\n",
      "scale: 1.1363, bias: -0.3891\n",
      "cases_num:  10\n",
      "times_count: 40\n",
      "scale: 1.1459, bias: -0.3966\n",
      "cases_num:  10\n",
      "times_count: 41\n",
      "scale: 1.1561, bias: -0.4037\n",
      "cases_num:  10\n",
      "times_count: 42\n",
      "scale: 1.1668, bias: -0.4105\n",
      "cases_num:  10\n",
      "times_count: 43\n",
      "scale: 1.1778, bias: -0.4169\n",
      "cases_num:  10\n",
      "times_count: 44\n",
      "scale: 1.1891, bias: -0.4229\n",
      "cases_num:  10\n",
      "times_count: 45\n",
      "scale: 1.2007, bias: -0.4287\n",
      "cases_num:  10\n",
      "times_count: 46\n",
      "scale: 1.2124, bias: -0.4342\n",
      "cases_num:  10\n",
      "times_count: 47\n",
      "scale: 1.2242, bias: -0.4394\n",
      "cases_num:  10\n",
      "times_count: 48\n",
      "scale: 1.2361, bias: -0.4445\n",
      "cases_num:  10\n",
      "times_count: 49\n",
      "scale: 1.2478, bias: -0.4494\n",
      "cases_num:  10\n",
      "times_count: 50\n",
      "scale: 1.2594, bias: -0.4542\n",
      "cases_num:  10\n",
      "times_count: 51\n",
      "scale: 1.2709, bias: -0.4588\n",
      "cases_num:  10\n",
      "times_count: 52\n",
      "scale: 1.2823, bias: -0.4633\n",
      "cases_num:  10\n",
      "times_count: 53\n",
      "scale: 1.2934, bias: -0.4677\n",
      "cases_num:  10\n",
      "times_count: 54\n",
      "scale: 1.3044, bias: -0.4720\n",
      "cases_num:  10\n",
      "times_count: 55\n",
      "scale: 1.3151, bias: -0.4761\n",
      "cases_num:  10\n",
      "times_count: 56\n",
      "scale: 1.3256, bias: -0.4802\n",
      "cases_num:  10\n",
      "times_count: 57\n",
      "scale: 1.3358, bias: -0.4842\n",
      "cases_num:  10\n",
      "times_count: 58\n",
      "scale: 1.3457, bias: -0.4882\n",
      "cases_num:  10\n",
      "times_count: 59\n",
      "scale: 1.3549, bias: -0.4922\n",
      "cases_num:  10\n",
      "times_count: 60\n",
      "scale: 1.3639, bias: -0.4961\n",
      "cases_num:  10\n",
      "times_count: 61\n",
      "scale: 1.3728, bias: -0.4999\n",
      "cases_num:  10\n",
      "times_count: 62\n",
      "scale: 1.3815, bias: -0.5035\n",
      "cases_num:  10\n",
      "times_count: 63\n",
      "scale: 1.3899, bias: -0.5071\n",
      "cases_num:  10\n",
      "times_count: 64\n",
      "scale: 1.3982, bias: -0.5105\n",
      "cases_num:  10\n",
      "times_count: 65\n",
      "scale: 1.4063, bias: -0.5138\n",
      "cases_num:  10\n",
      "times_count: 66\n",
      "scale: 1.4143, bias: -0.5170\n",
      "cases_num:  10\n",
      "times_count: 67\n",
      "scale: 1.4220, bias: -0.5201\n",
      "cases_num:  10\n",
      "times_count: 68\n",
      "scale: 1.4296, bias: -0.5231\n",
      "cases_num:  10\n",
      "times_count: 69\n",
      "scale: 1.4371, bias: -0.5259\n",
      "cases_num:  10\n",
      "times_count: 70\n",
      "scale: 1.4444, bias: -0.5286\n",
      "cases_num:  10\n",
      "times_count: 71\n",
      "scale: 1.4515, bias: -0.5312\n",
      "cases_num:  10\n",
      "times_count: 72\n",
      "scale: 1.4583, bias: -0.5337\n",
      "cases_num:  10\n",
      "times_count: 73\n",
      "scale: 1.4649, bias: -0.5361\n",
      "cases_num:  10\n",
      "times_count: 74\n",
      "scale: 1.4713, bias: -0.5385\n",
      "cases_num:  10\n",
      "times_count: 75\n",
      "scale: 1.4774, bias: -0.5408\n",
      "cases_num:  10\n",
      "times_count: 76\n",
      "scale: 1.4834, bias: -0.5430\n",
      "cases_num:  10\n",
      "times_count: 77\n",
      "scale: 1.4891, bias: -0.5451\n",
      "cases_num:  10\n",
      "times_count: 78\n",
      "scale: 1.4946, bias: -0.5472\n",
      "cases_num:  10\n",
      "times_count: 79\n",
      "scale: 1.5000, bias: -0.5491\n",
      "cases_num:  10\n",
      "times_count: 80\n",
      "scale: 1.5052, bias: -0.5510\n",
      "cases_num:  10\n",
      "times_count: 81\n",
      "scale: 1.5102, bias: -0.5527\n",
      "cases_num:  10\n",
      "times_count: 82\n",
      "scale: 1.5150, bias: -0.5544\n",
      "cases_num:  10\n",
      "times_count: 83\n",
      "scale: 1.5197, bias: -0.5560\n",
      "cases_num:  10\n",
      "times_count: 84\n",
      "scale: 1.5243, bias: -0.5575\n",
      "cases_num:  10\n",
      "times_count: 85\n",
      "scale: 1.5286, bias: -0.5590\n",
      "cases_num:  10\n",
      "times_count: 86\n",
      "scale: 1.5328, bias: -0.5603\n",
      "cases_num:  10\n",
      "times_count: 87\n",
      "scale: 1.5369, bias: -0.5616\n",
      "cases_num:  10\n",
      "times_count: 88\n",
      "scale: 1.5407, bias: -0.5629\n",
      "cases_num:  10\n",
      "times_count: 89\n",
      "scale: 1.5445, bias: -0.5640\n",
      "cases_num:  10\n",
      "times_count: 90\n",
      "scale: 1.5481, bias: -0.5651\n",
      "cases_num:  10\n",
      "times_count: 91\n",
      "scale: 1.5516, bias: -0.5661\n",
      "cases_num:  10\n",
      "times_count: 92\n",
      "scale: 1.5550, bias: -0.5670\n",
      "cases_num:  10\n",
      "times_count: 93\n",
      "scale: 1.5582, bias: -0.5679\n",
      "cases_num:  10\n",
      "times_count: 94\n",
      "scale: 1.5613, bias: -0.5687\n",
      "cases_num:  10\n",
      "times_count: 95\n",
      "scale: 1.5643, bias: -0.5695\n",
      "cases_num:  10\n",
      "times_count: 96\n",
      "scale: 1.5671, bias: -0.5702\n",
      "cases_num:  10\n",
      "times_count: 97\n",
      "scale: 1.5697, bias: -0.5709\n",
      "cases_num:  10\n",
      "times_count: 98\n",
      "scale: 1.5722, bias: -0.5715\n",
      "cases_num:  10\n",
      "times_count: 99\n",
      "scale: 1.5746, bias: -0.5722\n",
      "cases_num:  10\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "config_path = 'Config_files/XOR.yaml'\n",
    "params = parse(config_path)\n",
    "\n",
    "\n",
    "train_loader, test_loader = loadXOR.get_XOR(params['Network'])\n",
    "\n",
    "network_config = params['Network']\n",
    "n_steps = network_config['n_steps']\n",
    "batch_size = network_config['batch_size']\n",
    "epoch = 0\n",
    "glv.init(params)\n",
    "\n",
    "net = cnns.Network(params['Network'], params['Layers'],\\\n",
    "            list(train_loader.dataset[0][0].shape)).to(glv.device)\n",
    "\n",
    "err = loss.SpikeLoss(params['Network']).to(glv.device)\n",
    "optimizer = torch.optim.AdamW(net.get_parameters(),\\\n",
    "            lr=params['Network']['lr'], betas=(0.9, 0.999))\n",
    "flag = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "    if flag == 1:\n",
    "        break\n",
    "    flag=1\n",
    "targets = labels\n",
    "inputs.type(dtype)\n",
    "inputs = inputs.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "print(labels)\n",
    "print(inputs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "%matplotlib qt5\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for times_count in range(100):\n",
    "    \n",
    "    print(\"times_count:\", times_count)\n",
    "    save_fig('mem'+str(times_count))\n",
    "    save_fig('out'+str(times_count))\n",
    "    \n",
    "    outputs = net.forward(inputs, True)\n",
    "    plot_mov_fig()\n",
    "\n",
    "    loss_num = err.average(outputs, targets)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_num.backward()\n",
    "    plot_grad_fig()\n",
    "    plt.pause(0.01)\n",
    "    save_fig('err'+str(times_count))\n",
    "    save_fig('gra'+str(times_count))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
